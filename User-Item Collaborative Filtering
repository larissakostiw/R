---
title: "User-Item Recommendation Engines"
author: "Larissa Kostiw"
date: "13 August 2019"
---

```{r Data Processing}
library(data.table)
dataframe <- fread("file.csv")
dataframe <- dataframe %>% 
             select(User, Item) %>%
             filter(xxxxxxx)  #Perform any exclusions 
    
#Create a flag for the binary rating matrix
dataframe$flag <- 1    

```

```{r Binary Rating Matrix}
#Prep for transposition
overall_md<-melt(dataframe, id=(c("User", "Item")))
#Create the SCV with users down and each column per item with a flag.
overall_2<- dcast(overall_md, User~Item, value="Flag", fun.aggregate = mean)

#Replace NaN with 0
is.nan.data.frame <- function(x)
do.call(cbind, lapply(x, is.nan))

overall_2[is.nan(overall_2)] <- 0 #Replace NA with 0.

library(recommenderlab)

#Convert to binary rating matrix
overall_matrix<- as.matrix(overall_2[,2:ncol(overall_2)])#Convert to matrix
matrix_binary<- as(overall_matrix, "binaryRatingMatrix")  #Make a binary ratings matrix
```


```{r Models}
#Similarity Matrix to compute items that are similar to one another
overall_similarity<-similarity(matrix_binary, method="jaccard", which="items")

#Determine which parameters to use by examining the precision plots
algorithms <- list(`user-based CF 50` = list(name = "UBCF",param = list(method = "Jaccard", nn = 50)),
                   different_parameters = xxx,,, 
                   )
                                         
scheme <- evaluationScheme(matrix_binary, method = "cross", k = 4,given = 1)
results <- evaluate(scheme, algorithms, n = c(5,10))

#Plot results 
plot(results, annotate = c(1, 3), legend = "right") #ROC Curve
plot(results, "prec/rec", annotate = 3) #Precision/Recall Plot

#Apply the selected parameters
recc_model <- Recommender(data = matrix_binary, method = "UBCF", 
                          parameter = list(method = "Jaccard",
                                           nn=500))
model_details <- getModel(recc_model)
model_details

#Obtain ratings and create df
recc_predicted <- predict(object = recc_model, newdata = matrix_binary, n = 123, type="ratings")
ibcf_scores<-as(recc_predicted, "list") #Create a list of the scores
ibcf_list_scores<-ldply(ibcf_scores, rbind) #Row bind
ibcf_list_scores[is.na(ibcf_list_scores)]<-0 #Convert NA to 0.


#Obtain top N recommended items  and create df
recc_predicted_list2<-predict(object=recc_model,newdata= matrix_binary,type="topNList", n=20) 
recc_predicted_list2_a<- as(recc_predicted_list2, "list") #Createa list of the brands
recc_predicted_list2_b<-ldply(recc_predicted_list2_a, rbind) #Row bind
recc_predicted_list2_b[is.na(recc_predicted_list2_b)]<-0 #Convert NA to 0

#Test and validation
validate_matrix<- evaluationScheme(matrix_binary, method="split", train=xx, given=1)
v_model<- Recommender(getData(validate_matrix, "train"),"UBCF")
test<- predict(v_model, getData(validate_matrix, "known"), type="ratings")
error_matrix<- calcPredictionAccuracy(test, getData(validate_matrix, "unknown")
#Examine results
```

```{r Explore ratings & Finalise Outputs}
#Examine the rating frequency and remove ratings based on a specific threshold (remove very low ratings)
ibcf_list_scores[,2:ncol(ibcf_list_scores)][ibcf_list_scores[,2:ncol(ibcf_list_scores)] < THRESHOLD] <- 0 
```

